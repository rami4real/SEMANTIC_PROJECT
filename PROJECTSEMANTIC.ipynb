{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import unicodedata\n",
        "\n",
        "# Définit les variantes de “de”\n",
        "PREPOSITIONS = [\n",
        "    r\"\\bde la\\b\",\n",
        "    r\"\\bde\\b\",\n",
        "    r\"\\bdu\\b\",\n",
        "    r\"\\bdes\\b\",\n",
        "    r\"\\bd’\\b\",\n",
        "    r\"\\bd’un\\b\",\n",
        "    r\"\\bd’une\\b\",\n",
        "    r\"\\bde l’\\b\"\n",
        "]\n",
        "\n",
        "pattern = re.compile(\n",
        "    rf\"(.+?)\\s+(?:{'|'.join(PREPOSITIONS)})\\s+(.+?)(?:\\s*\\|\\s*(.*))?$\",\n",
        "    flags=re.IGNORECASE\n",
        ")\n",
        "\n",
        "def nettoyer_texte(s: str) -> str:\n",
        "    \"\"\"Nettoyage de base + amélioré : trim, minuscules, retire ponctuation, accents, espaces multiples.\"\"\"\n",
        "    if s is None:\n",
        "        return None\n",
        "    s = s.strip()\n",
        "    s = s.lower()\n",
        "    # Normaliser accents → forme de base (optionnel)\n",
        "    s = unicodedata.normalize('NFKD', s)\n",
        "    s = ''.join([c for c in s if not unicodedata.combining(c)])\n",
        "    # Retirer ponctuation interne (on considère que mot1/mot2 sont des mots simples)\n",
        "    s = re.sub(r\"[^\\w\\s]\", \" \", s)  # remplace tout ce qui n’est pas lettre/chiffre/_/espace\n",
        "    # Remplacer chiffres si non pertinents (ex ici on retire les chiffres)\n",
        "    s = re.sub(r\"\\d+\", \"\", s)\n",
        "    # Remplacer plusieurs espaces par un seul\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    s = s.strip()\n",
        "    return s\n",
        "\n",
        "def extraire_paires(ligne: str):\n",
        "    m = pattern.match(ligne)\n",
        "    if not m:\n",
        "        return None\n",
        "    mot1_raw, mot2_raw, relation_raw = m.groups()\n",
        "    mot1 = nettoyer_texte(mot1_raw)\n",
        "    mot2 = nettoyer_texte(mot2_raw)\n",
        "    relation = nettoyer_texte(relation_raw) if relation_raw else \"r_has_causatif\"\n",
        "    # On peut rejeter les cas où mot1 ou mot2 après nettoyage sont vides\n",
        "    if not mot1 or not mot2:\n",
        "        return None\n",
        "    return mot1, mot2, relation\n",
        "\n",
        "def traiter_fichier(input_path: str, output_csv: str):\n",
        "    résultats = []\n",
        "    with open(input_path, encoding=\"utf‑8\") as f:\n",
        "        for lineno, ligne in enumerate(f, start=1):\n",
        "            ligne = ligne.strip()\n",
        "            if not ligne:\n",
        "                continue\n",
        "            paire = extraire_paires(ligne)\n",
        "            if paire:\n",
        "                mot1, mot2, relation = paire\n",
        "                résultats.append({\"mot1\": mot1, \"mot2\": mot2, \"relation\": relation})\n",
        "            else:\n",
        "                # Optionnel : logger ou compter\n",
        "                # print(f\"Ligne {lineno} non extraite : {ligne}\")\n",
        "                pass\n",
        "\n",
        "    df = pd.DataFrame(résultats)\n",
        "    # Optionnel : drop duplicates\n",
        "    df = df.drop_duplicates(subset=[\"mot1\", \"mot2\", \"relation\"])\n",
        "    # Optionnel : reset index\n",
        "    df = df.reset_index(drop=True)\n",
        "    df.to_csv(output_csv, index=False, encoding=\"utf‑8\")\n",
        "    print(f\"{len(résultats)} paires extraites, écrites dans {output_csv}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    traiter_fichier(\"/content/sample_data/liste_paires.txt\", \"paires_nettoyees.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsATYy22WLKs",
        "outputId": "cd3a8a8e-6b0e-4dbe-bda4-10c68dee64e8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16 paires extraites, écrites dans paires_nettoyees.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QbcdLF6QXpUB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}